{
  
    
        "post0": {
            "title": "Capstone - Automating Fall Detection with Machine Learning",
            "content": "Capstone: Automating Fall Detection with Machine Learning . Processing video to detect a fall on camera . Context . In my final two semesters of college I completed a capstone project in coordination with a local company - Vivint SmartHome (VSH). VSH has a line of in-home cameras that customers purchase for home security. Two fellow classmates and I were tasked with prototyping a new feature for them: automatically detecting if a person has fallen over. Our little 3-person team was multidisciplinary, and, as is the case in most undergraduate group projects, we each had varying interests in different aspects of the project. I was very interested in ML at the time and relished the opportunity to tackle a real-world problem with ML. As such, I led the effort on researching and designing the data processing, modeling, and overall ML approach, and that will be the focus of this blog post. . If you’re interested in using ML to process video, this walkthrough could prove highly useful; it’s a simple technical design that’s great for beginners! What follows is a conceptual overview of my specific problem, a description of my technical approach, and a presentation of my results. . Background . Falling is a significant problem for elderly people; over 30% of population age 65+ falls annually, and falls are responsible for over 50% of hospitalizations in that demographic. Injuries and hospitalization as the result of a fall are a large risk. VHS has existing in-home security cameras that are connected to the internet. With this project, I developed an algorithm and data processing pipeline to automatically detect a fall. If this were put into production it could notify family members or emergency services immediately in the event of a fall, if the customer enabled this functionality. (For example, if a family installs such a system in the home of their elderly relative, they could enable this feature. When grandkids come to visit, they could disable it to avoid unnecessary alerts.) . Initial Assumptions . Since this was a simple proof-of-concept project for VHS, we allowed ourselves several limiting assumptions in our data set. These assumptions were: . only one person in the frame at a time . | the falling motion of the individual is perpendicular to the camera . | no concept of recovering from a fall, i.e. if a fall is detected on camera, it is classified as a fall even if the individual gets back up after the fall. . | fall event not occluded; the majority of the fall event is visible to the camera and not hidden behind furniture, etc. . | . Data Collection . Since no relatively simple, labeled data set was available to us, we curated our data set ourselves — that’s right, we filmed ourselves falling over and over again in a controlled environment, much to the pleasure of our fellow classmates and professors. . . Subjects purposefully varied in height, width, and color of apparel to give variety to our data set and prevent models from learning from inappropriate, non-generalizable features. . A data augmentation process was employed to generate multiple two-second clips (60 frames for 30fps cameras) from a single video. Borrowing the concept of stride from CNNs, a stride length of 30 frames was used to capture overlap between clips. The process is shown below with an eight second video (240 frames), which generates seven distinct two-second data points. . . This resulted in a dataset of 424 2-second videos. To match the natural imbalance between fall and non-fall videos, 20% of our dataset are clips of fall events and the other 80% are clips of non-fall events. .",
            "url": "https://jaxondk.github.io/ds-blog/2020/04/18/Capstone-ML.html",
            "relUrl": "/2020/04/18/Capstone-ML.html",
            "date": " • Apr 18, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Markovmodels",
            "content": "Markov Models in Financial ML . Markov Models attempt to explain a random process that depends on the current event but not on the previous events. It’s a special case of a probabilistic/stochastic model.The Markov Chain Model is for a system whose states are fully observable. The Hidden Markov Model (HMM) is for a system whose states are only partially observable. Markov Models output the expected probability of some event or events given the current state 1. . Notice that Markov models deal with sequences of inputs - they are for time-series data. A Deep Learning architecture that is also meant to deal with time-series data is the RNN. Markov Models are simpler but also make some broad assumptions that often are not true. When the assumptions are true, however, you may get better results using a HMM than by using a RNN. If you have a large amount of data, though, the RNN will likely outperform the HMM even if the assumptions for an HMM are true 2. . Under Construction . When the current data set I’m iterating on calls for time-series data I will continue this post. . References . [1]: https://blog.quantinsti.com/markov-model/ . [2]: https://stats.stackexchange.com/a/366430 .",
            "url": "https://jaxondk.github.io/ds-blog/architecture/2020/03/30/MarkovModels.html",
            "relUrl": "/architecture/2020/03/30/MarkovModels.html",
            "date": " • Mar 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Ml Math",
            "content": "Cheat Sheet: Math for Machine Learning . Motivation . I often find myself needing to look up various mathematical components of machine learning models, loss functions, activation functions, etc. This is a space where I hope to keep a quick reference for such things, and also to get into the nitty gritty of some math things that previously I’ve always just accepted at face value or simply glanced over. . Loss functions . KL Divergence . Kullback-Leibler Divergence (also called relative entropy) is a measure comparing a probability distribution to another, ground-truth distribution. A value of 0 signifies that the two distributions are identical. .",
            "url": "https://jaxondk.github.io/ds-blog/math/2020/03/09/ML-Math.html",
            "relUrl": "/math/2020/03/09/ML-Math.html",
            "date": " • Mar 9, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Tabnet",
            "content": "Exploring TabNet by Google . Motivation for Post . At my company we’re investigating deep learning as it applies to financial tabular data. This is a fairly under-researched area and so I’ve been conducting a lot of my own experiments. This has been great (I’ve learned a ton), but when you’re at a start-up, “speedy results” is the name of the game. That’s why I was thrilled to discover that Google recently published a paper called TabNet: Attentive Interpretable Tabular Learning. This post will essentially be my notepad as I explore the ins and outs of this approach. As such, this post will be very disorganized; I hope to write up a post that is more suited for public consumption in the future. . Important terms I felt ought to be defined for readers, or terms that I was familiar with but not well-versed in, are defined in a glossary at the end of the post . 1 Introduction . Tree-based models still dominate the tabular world, largely because (1) there’s no canonical, standard DNN architecture for tabular data that performs well and (2) tree-based models are typically more interpretable than DNNs. TabNet attempts to achieve both high performance and interpretability. Interpretability is achieved by using soft feature selection via attention mechanisms. This feature selection occurs at each “decision step” of the model by using sequential attention. . TabNet also provides a method for self-supervised learning on tabular data (read: pre-training), which makes it attractive for data sets with a lot of unlabeled data available. . 3 TabNet for Tabular Learning . The authors claim that the features selection not only aids interpretability but also improves performance because learning is focused on the most important/salient features. (“Through sparse selection of the most salient features, the learning capacity of a decision step is not wasted on irrelevant features, and thus the model becomes more parameter efficient.”) Something else that’s cool is that they claim the higher dimensionality of TabNet mimics ensembling done in tree-based methods. . Categorical features are mapped to learned embeddings. No global normalization is applied to the data set; only batch norm is applied. (Note - that does not mean you should not normalize your features before passing them into TabNet; you should!) Similar to methods in vision and language processing, TabNet process a data point over several steps and is regressive - the input to step i is the output from step (i-1). Each step is trying to limit the high dimensionality space to the most salient inputs. (Think of a CNN, how it convolves groups of inputs down to smaller dimensions, keeping only the most important parts necessary for a correct prediction. Or think of an LSTM, which has gates between steps that attempt to learn the most important information to let pass through. TabNet is really similar to an LSTM in that way.) . — Under construction — . 4 Tabular Self-Supervised Learning . Hyperparameters . $ gamma$ - relaxation parameter; determines at how many decision steps a feature is allowed to be used. If $ gamma = 1$, features are forced to only be used at one decision step. As $ gamma$ increases, features can be used at multiple decision steps. | . Glossary . feature selection - Identifying some subset of the provided features that are most useful for the prediction task. There are two broad types: global feature selection and local or instance-wise feature selection. Global feature selection is based on the entire training set, local feature selection is obviously on a per-data-point basis | salient - important; what matters to the network. | sequential attention | .",
            "url": "https://jaxondk.github.io/ds-blog/papers/tabular/architecture/2020/02/26/TabNet.html",
            "relUrl": "/papers/tabular/architecture/2020/02/26/TabNet.html",
            "date": " • Feb 26, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jaxondk.github.io/ds-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jaxondk.github.io/ds-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Yours Truly . I graduated with a B.S. in Computer Science at Brigham Young University with a Business Minor. Most of my internships were all for software development positions, and then around my senior year I realized I was fascinated with machine learning and wanted to pivot into that field. I was fortunate enough to land a position as a Machine Learning Researcher at Stratesis Technologies, LLC - a technology-based hedge fund. While there I discovered the fastai library and have worked hard to transition the company to deep learning. . My dream is to solve real-world problems - especially in the lives of those who suffer disproportionately. I feel that I have received so much but up to this point have given so little in comparison. I hope to acquire skill sets that will allow me to fulfill this dream, and I believe I am making real progress to that end. If any of you are working on solving societal problems such as poverty, homelessness, recidivism, healthcare, etc. – especially by using data science – please feel free to contact me using the links in the footer. . I also think about the potential of humanity developing Artificial Super Intelligence in my lifetime, and I’m concerned about the consequences of such a development. It seems that no matter what we do, many actors (businesses, institutions, and entire governemnts) will race toward developing ASI despite the immense negative consequences it could have. If done safely, however, I am also excited about the incredible opportunities. All of the societal problems I discussed above could be solved by an ASI, if well-designed. Because of this, I feel we must strive to do what we can to progress the field of safe AGI (artificial general intelligence) and ASI. .",
          "url": "https://jaxondk.github.io/ds-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jaxondk.github.io/ds-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}